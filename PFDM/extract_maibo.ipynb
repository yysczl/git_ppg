{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faba9bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.633114Z",
     "start_time": "2024-10-23T06:07:58.622319Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import _ctypes\n",
    "import sys\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, find_peaks, peak_prominences\n",
    "from itertools import chain\n",
    "import math\n",
    "from scipy.signal import medfilt\n",
    "import scipy.io as io\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d #从 SciPy 导入插值函数\n",
    "from scipy.signal import butter, filtfilt, find_peaks, peak_prominences\n",
    "from scipy import integrate\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from scipy.signal import argrelmax, argrelmin, firwin, convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c232c9fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.664076Z",
     "start_time": "2024-10-23T06:07:58.634111Z"
    }
   },
   "outputs": [],
   "source": [
    "'''巴特沃斯滤波'''\n",
    "def butter_bandpass_1(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    \n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    return b, a\n",
    "        \n",
    "def apply_filtering_1(signal):\n",
    "    # sampling freq\n",
    "    #采样频率\n",
    "    fs = 45\n",
    "    b, a = butter_bandpass_1(0.5, 8, fs, order=4)\n",
    "    \n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def systolic_peaks_2(signal):\n",
    "    ''' Returns list of found systolic peaks in whole signal. Identified as maxima. Required distance between peaks set to 22'''\n",
    "    '''返回在整个信号中找到的收缩峰的列表。确定为最大值。峰值之间的所需距离设置为22'''\n",
    "    return find_peaks(signal, distance=20)[0]\n",
    "\n",
    "#'''谷值--起点''''\n",
    "def tfn_points_2(signal):\n",
    "    ''' Returns list of tfn points (beats boundaries) as minimums of signal with distance min 25 between eachother'''\n",
    "    '''返回tfn点（拍边界）列表，作为信号的最小值，彼此之间的距离最小为25'''\n",
    "    #在这里，我使用还原信号，得到高于0的峰值\n",
    "    # here I use reverted signal and get peaks above 0 \n",
    "    return find_peaks(signal*(-1), height=0, distance=20)[0]\n",
    "\n",
    "def beat_segmentation(signal):\n",
    "    \n",
    "    ''' Returns list of beats from signal and list of corresponding systolic peak index'''\n",
    "    '''返回信号中的搏动列表和相应收缩峰指数列表'''\n",
    "    \n",
    "    systolics = systolic_peaks_2(signal)\n",
    "    tfns = tfn_points_2(signal)\n",
    "    \n",
    "    #beats:节拍;systolic\n",
    "    beats, systolic = [], []\n",
    "    \n",
    "    for i in range(len(tfns)-1):\n",
    "        start = tfns[i]\n",
    "        end = tfns[i+1]\n",
    "        segment = np.arange(start, end)\n",
    "        l = [f in systolics for f in segment]\n",
    "        \n",
    "        # if there is only one systolic peak between minima its a beat\n",
    "        #如果最小值之间只有一个收缩峰，那就是一次跳动\n",
    "        if list(map(bool, l)).count(True) == 1: \n",
    "            # apply normalization, reshaping is required\n",
    "            #应用规范化，需要重塑\n",
    "            bshape = signal[segment].shape\n",
    "            normalized_beat = normalize(signal[segment].reshape(1, -1))\n",
    "            beats.append(normalized_beat.reshape(bshape))\n",
    "            systolic.append(np.where(l)[0][0])\n",
    "    return beats, systolic\n",
    "#第一个低谷\n",
    "def dicrotic_notch(beat, systolic):\n",
    "    '''Returns index of detected dicrotic notch in a beat. If not found returns 0'''\n",
    "    '''返回在拍中检测到的第一个低谷的索引。如果未找到，则返回0'''\n",
    "\n",
    "    derviative = np.diff(beat[systolic:])\n",
    "    point = find_peaks(derviative)[0]\n",
    "    corrected = 0\n",
    "    \n",
    "    if len(point) > 0:\n",
    "        corrected =  systolic + point[-1]\n",
    "        \n",
    "    return corrected\n",
    "#第二个峰值\n",
    "def diastolic_peak(beat, systolic):\n",
    "    '''Returns index of detected diastolic peak in a beat. If not found returns 0'''\n",
    "    '''返回检测到的搏动中舒张峰值的指数。如果未找到，则返回0'''\n",
    "   \n",
    "    derviative = np.diff(np.diff(beat[systolic:]))\n",
    "    point = find_peaks(derviative*(-1))[0]\n",
    "    corrected = 0\n",
    "    \n",
    "    if len(point) > 0:\n",
    "        corrected = systolic + point[0]+1\n",
    "        if abs(beat[corrected]) >= abs(0.2*beat[corrected - 1]):\n",
    "            return corrected\n",
    "        else: return 0\n",
    "        \n",
    "    return corrected\n",
    "#第一个低谷\n",
    "def dicrotic_notch(beat, systolic):\n",
    "    '''Returns index of detected dicrotic notch in a beat. If not found returns 0'''\n",
    "    '''返回在拍中检测到的第一个低谷的索引。如果未找到，则返回0'''\n",
    "    \n",
    "    derviative = np.diff(beat[systolic:])\n",
    "    point = find_peaks(derviative)[0]\n",
    "    corrected = 0\n",
    "    \n",
    "    if len(point) > 0:\n",
    "        corrected =  systolic + point[0]-1\n",
    "        \n",
    "    return corrected\n",
    "def peaks_detection(beats, systolics):\n",
    "    '''Returns created dataframe with beat values and critical points indices'''\n",
    "    '''返回创建的带有拍值和临界点索引的数据帧'''\n",
    "    \n",
    "    dicrotics = []\n",
    "    diastolics = []\n",
    "    \n",
    "    for b, s in zip(beats, systolics):\n",
    "        tnn = dicrotic_notch(b,s)\n",
    "        tdn = diastolic_peak(b,s)\n",
    "        #第一个低谷\n",
    "        dicrotics.append(tnn)\n",
    "        #第二个峰值\n",
    "        diastolics.append(tdn)\n",
    "    \n",
    "    result = np.array([beats, systolics, dicrotics, diastolics], dtype=object)\n",
    "    #print(result)\n",
    "    #print(result[2])\n",
    "    #print(result[3])\n",
    "    #去掉那些没有发现双循环和舒张药的\n",
    "    # remove those where dicrotics and diastolics weren't found\n",
    "    \n",
    "    result = result[..., result[2] > 0]\n",
    "    #print(\"低:\",np.array(result).shape)\n",
    "    result = result[..., result[3] > 0]\n",
    "    #print(\"高:\",np.array(result).shape)\n",
    "    #输出形状为（4，nb），其中nb是拍数\n",
    "    # output shape is (4, nb) where nb is number of beats\n",
    "    return result.T\n",
    "\n",
    "\n",
    "def extract_PPG(i):\n",
    "    dataAnxiety = []\n",
    "    # 可视化点检测\n",
    "    fil = apply_filtering_1(i)\n",
    "    systolics = systolic_peaks_2(fil)\n",
    "    tfns = tfn_points_2(fil)\n",
    "    beats, systolics= beat_segmentation(fil)\n",
    "    #print(\"b:\",np.array(beats).shape)\n",
    "    #print(\"s:\",np.array(systolics).shape)\n",
    "    beats_features = peaks_detection(beats, systolics)\n",
    "    new_list2 = []\n",
    "    number = 0\n",
    "    #print(len(beats_features))\n",
    "    for beat, systolic, dicrotic, diastolic in beats_features:\n",
    "        buhege = []\n",
    "        if dicrotic < diastolic:\n",
    "            new_list1 = []\n",
    "            for wave in list(beat):\n",
    "                new_wave = (wave - np.min(list(beat))) / (np.max(list(beat)) - np.min(list(beat)))\n",
    "                new_list1.append(new_wave)\n",
    "            x = np.linspace(0,len(new_list1),len(new_list1))\n",
    "            xvals = np.linspace(0,len(new_list1),80)\n",
    "            yinterp = np.interp(xvals,x,new_list1)\n",
    "            new_list2.append(list(yinterp))\n",
    "        else:\n",
    "            buhege.append(beat)\n",
    "    #print(np.array(new_list2).shape)\n",
    "#     print(len(new_list2))\n",
    "    if len(new_list2) > 40:\n",
    "        dataAnxiety = dataAnxiety + new_list2[0:40]\n",
    "    else:\n",
    "        sum_=new_list2\n",
    "        for i in range(int(40//len(new_list2)+1)):\n",
    "            sum_ = sum_+new_list2\n",
    "        dataAnxiety = dataAnxiety + sum_[0:40]\n",
    "    return np.array(dataAnxiety).reshape(1,-1,40)\n",
    "\n",
    "def sampling_freq(signal, time=90):\n",
    "    # print(len(signal))\n",
    "    return int(len(signal) / time)\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "\n",
    "    low = lowcut / nyq\n",
    "    # high = highcut / nyq\n",
    "    ##防止high取到1，因为范围时（0，1）0和1都不可取到\n",
    "    high = min(highcut, 0.999) / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "\n",
    "    return b, a\n",
    "\n",
    "def apply_filtering(signal):\n",
    "    # sampling freq\n",
    "    # 采样频率\n",
    "    fs = sampling_freq(signal)\n",
    "    print(fs)\n",
    "    b, a = butter_bandpass(0.5, 10, fs, order=4)\n",
    "\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def systolic_peaks_1(signal):\n",
    "    return find_peaks(signal, distance=18)[0]\n",
    "\n",
    "def tfn_points_1(signal):\n",
    "    # 在这里，我使用还原信号，并获得高于0的峰值\n",
    "    return find_peaks(signal * (-1), height=0, distance=25)[0]\n",
    "\n",
    "###提取脉率变异性\n",
    "def PRV(PPG):\n",
    "    PRV = []\n",
    "    # print(data.shape)\n",
    "    # print('PPGlen',len(PPG))\n",
    "    # 可视化点检测\n",
    "    new_list2 = []\n",
    "    fil = apply_filtering(PPG)\n",
    "    systolics = systolic_peaks_1(fil)\n",
    "    tfns = tfn_points_1(fil)\n",
    "\n",
    "    PP_list1 = []\n",
    "    PP_list2 = []\n",
    "    cnt = 0\n",
    "    while (cnt < (len(systolics) - 1)):\n",
    "        PP_interval = (systolics[cnt + 1] - systolics[cnt])  # 以样本数计算节拍之间的距离\n",
    "        PP_list1.append(PP_interval)  # 附加到列表\n",
    "        cnt += 1\n",
    "    cnt = 1\n",
    "    rate = len(PPG) / 90\n",
    "    c1 = rate * 0.5\n",
    "    while (cnt < len(PP_list1) - 1):\n",
    "        if PP_list1[cnt] > rate or PP_list1[cnt] < c1:\n",
    "            PP_list1[cnt] = (PP_list1[cnt - 1] + PP_list1[cnt + 1]) / 2\n",
    "        cnt = cnt + 1\n",
    "    num = len(PPG) / 40\n",
    "    new_lst1 = np.divide(PP_list1, num)\n",
    "    if len(new_lst1) < 80:\n",
    "        # 如果长度不够80，用均值填充\n",
    "        # 计算 new_lst1 的均值\n",
    "        mean_value = np.mean(new_lst1)\n",
    "        # 创建一个迭代器，它首先产生 new_lst1 的所有元素，然后是 mean_value 的重复\n",
    "        padded_iter = chain(new_lst1, [mean_value] * (80 - len(new_lst1)))\n",
    "        # 将迭代器转换为列表\n",
    "        new_lst2 = list(padded_iter)\n",
    "    else:\n",
    "        new_lst2 = new_lst1[0:80]\n",
    "    #     print(len(new_lst2))\n",
    "    #     print(new_lst2)\n",
    "    PRV.append(new_lst2)\n",
    "    return np.array(PRV).reshape(1,-1,1)\n",
    "\n",
    "def PupilWaveLoadAndProcess(txtpath):\n",
    "    emo_index = ['PeaceHeartRate', 'HappyHeartRate', 'SadHeartRate', 'AnxietyHeartRate', 'StressHeartRate']\n",
    "    data=[]\n",
    "    txtPath = txtpath\n",
    "    calm_list = []\n",
    "    happy_list = []\n",
    "    sad_list = []\n",
    "    anxiety_list = []\n",
    "    stress_list = []\n",
    "\n",
    "    for emo in emo_index:\n",
    "        #read the txt file to extract the pupil diameter\n",
    "        path = os.path.join(txtPath,\"{0}.txt\".format(emo))\n",
    "        with open(path, \"r\") as f:\n",
    "            StrLines = f.readlines()\n",
    "        PupilDiameter = []\n",
    "        for line in StrLines:\n",
    "            try:\n",
    "                Diameter = re.findall(\"ppg:(.*?),\", line)\n",
    "                PupilDiameter.append(float(Diameter[0]))\n",
    "            except Exception:\n",
    "                Diameter = re.findall('D:(.*?);', line)\n",
    "                if Diameter == []:\n",
    "                    Diameter = re.findall('D=(.*?);', line)\n",
    "\n",
    "                PupilDiameter.append(float(Diameter[0]))\n",
    "        #Deal with the defalut data (fill with the former data of the series)\n",
    "        if emo == 'HappyHeartRate':\n",
    "            happy_list = PupilDiameter\n",
    "        elif emo == 'PeaceHeartRate':\n",
    "            calm_list = PupilDiameter\n",
    "        elif emo == 'SadHeartRate':\n",
    "            sad_list = PupilDiameter\n",
    "        elif emo == 'AnxietyHeartRate':\n",
    "            anxiety_list = PupilDiameter\n",
    "        else:\n",
    "            stress_list = PupilDiameter\n",
    "\n",
    "#     peace_avg = np.average(calm_list[-1])\n",
    "#     joyful_differiential = normalization(happy_list - peace_avg)\n",
    "#     sad_differiential = normalization(sad_list - peace_avg)\n",
    "#     anxiety_differiential = normalization(anxiety_list - peace_avg)\n",
    "#     stress_differiential = normalization(stress_list - peace_avg)\n",
    "\n",
    "#     data1 = np.array([joyful_differiential, sad_differiential],dtype=np.float)\n",
    "#     data1 = data1.reshape(1,2048,2)\n",
    "\n",
    "#     data2 = np.array([joyful_differiential, sad_differiential, anxiety_differiential, stress_differiential],dtype=np.float)\n",
    "#     data2 = data2.reshape(1,2048,4)\n",
    "    calm_list = np.array(calm_list,dtype=np.float)\n",
    "    happy_list = np.array(happy_list,dtype=np.float)\n",
    "    sad_list = np.array(sad_list,dtype=np.float)\n",
    "    anxiety_list = np.array(anxiety_list,dtype=np.float)\n",
    "    stress_list =np.array(stress_list,dtype=np.float)\n",
    "    \n",
    "    return calm_list,happy_list,sad_list,anxiety_list,stress_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7962d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.680047Z",
     "start_time": "2024-10-23T06:07:58.665073Z"
    }
   },
   "outputs": [],
   "source": [
    "path_=r'E:\\数据集\\北工大第二批202109-202204年校内\\原始数据'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d814f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.695348Z",
     "start_time": "2024-10-23T06:07:58.681044Z"
    }
   },
   "outputs": [],
   "source": [
    "folders=os.listdir(path_)[:93]\n",
    "folders.remove('DL023')\n",
    "folders.remove('DL039')\n",
    "folders.remove('DL036')\n",
    "folders.reverse()\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a515b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.743339Z",
     "start_time": "2024-10-23T06:07:58.695348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\数据集\\北工大第二批202109-202204年校内\\原始数据\\S039\\heartRateData\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\数据集\\\\北工大第二批202109-202204年校内\\\\原始数据\\\\S039\\\\heartRateData\\\\PeaceHeartRate.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7d659911cd85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#ori_data=PupilWaveLoadAndProcess(path_p)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPupilWaveLoadAndProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdata_PRV\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPRV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdata_PPG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextract_PPG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f57b5f741cb0>\u001b[0m in \u001b[0;36mPupilWaveLoadAndProcess\u001b[1;34m(txtpath)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;31m#read the txt file to extract the pupil diameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxtPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"{0}.txt\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mStrLines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mPupilDiameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\数据集\\\\北工大第二批202109-202204年校内\\\\原始数据\\\\S039\\\\heartRateData\\\\PeaceHeartRate.txt'"
     ]
    }
   ],
   "source": [
    "heartPRV=[]\n",
    "heartPPG=[]\n",
    "heartLabel=[]\n",
    "for folder in folders:\n",
    "    path_f=os.path.join(path_,folder)\n",
    "    path_p=os.path.join(path_f,\"heartRateData\")\n",
    "    print(path_p)\n",
    "    #ori_data=PupilWaveLoadAndProcess(path_p)\n",
    "    for i,data in enumerate(PupilWaveLoadAndProcess(path_p)):\n",
    "        data_PRV=PRV(data)\n",
    "        data_PPG=extract_PPG(data)\n",
    "        heartPRV.append(data_PRV)\n",
    "        heartPPG.append(data_PPG)\n",
    "        heartLabel.append(i)\n",
    "    print(np.array(heartPPG).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbdc28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.744336Z",
     "start_time": "2024-10-23T06:07:58.744336Z"
    }
   },
   "outputs": [],
   "source": [
    "heartPRV_=np.array(heartPRV).reshape(-1,80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af33de0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T06:07:58.744336Z",
     "start_time": "2024-10-23T06:07:58.744336Z"
    }
   },
   "outputs": [],
   "source": [
    "print(heartPRV_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartPPG_=np.array(heartPPG).reshape(-1,80,40)\n",
    "heartlabel_=np.array(heartLabel)\n",
    "print(heartPRV_.shape)\n",
    "print(heartPPG_.shape)\n",
    "print(heartlabel_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19796f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('heartPRV.npy',heartPRV_)\n",
    "np.save('heartPPG.npy',heartPPG_)\n",
    "np.save('heartLabel.npy',heartlabel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8269d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
